{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4G1sSRvG3ER"
   },
   "source": [
    "# 뉴스 카테고리 다중분류 - 번외"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 개요\n",
    "텐서플로 데이터셋 중 하나인 '로이터 뉴스 주제 분류'에 대한 SVM 모델을 구축하고 테스트합니다.\n",
    "GLoVe 모델을 이용하여 토큰 임베딩을 구축하고, 이것을 이용해 유의어를 교체하는 방식의 텍스트 증강을 시행한 데이터로 2차 테스트하고, 텍스트 증강전후의 성능을 비교합니다.\n",
    "\n",
    "## 코드 구성\n",
    "코드는 크게 세 부분으로 나뉩니다.\n",
    "\n",
    "- 데이터 전처리 (함수)\n",
    "\n",
    "로이터 뉴스 데이터에 대해서, 텍스트를 딕셔너리로 바꾸고, 딕셔너리를 다시 디코딩하는 기능을 갖춘 함수입니다.\n",
    "\n",
    "- 데이터 증강을 위한 GloVe 모델 구축\n",
    "\n",
    "GloVe 모델로 단어 임베딩을 만들고, 이를 활용한 유의어 사전으로 단어를 교체해서 텍스트를 증강하고 이를 전처리하는 부분입니다.\n",
    "\n",
    "- 모델 구축 (함수)\n",
    "\n",
    "SVM 모델과 하이퍼 파라미터 설정을 하는 부분입니다.\n",
    "\n",
    "- 모델 실행결과 저장 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.21.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 셸 환경에서 명령어 실행\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3890,
     "status": "ok",
     "timestamp": 1699457657774,
     "user": {
      "displayName": "­김정현",
      "userId": "07015025296255556159"
     },
     "user_tz": -540
    },
    "id": "Azy8cna_iKdJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# 로이터 데이터셋을 로드하고 전처리하는 함수\n",
    "def load_and_preprocess_data(num_words=None):\n",
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
    "    \n",
    "    word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "    # 인덱스에서 단어로의 매핑을 생성합니다.\n",
    "    index_to_word = {index + 3: word for word, index in word_index.items()}\n",
    "    # 특수 토큰을 추가합니다.\n",
    "    for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "        index_to_word[index] = token\n",
    "    \n",
    "    # 훈련 데이터와 테스트 데이터를 텍스트로 디코딩합니다.\n",
    "    decoded_x_train = [' '.join([index_to_word.get(i, '?') for i in sequence]) for sequence in x_train]\n",
    "    decoded_x_test = [' '.join([index_to_word.get(i, '?') for i in sequence]) for sequence in x_test]\n",
    "    \n",
    "    return decoded_x_train, y_train, decoded_x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe 모델을 Word2Vec 포맷으로 변환한 후 로드하는 함수\n",
    "def load_glove_model(glove_input_file, word2vec_output_file):\n",
    "    glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "    model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "    return model\n",
    "\n",
    "# TF-IDF와 GloVe 모델을 사용하여 단어를 교체함으로써 데이터를 증강하는 함수\n",
    "def augment_data_by_replacing_words(texts, glove_model, tfidf_vectorizer):\n",
    "    augmented_texts = []\n",
    "    # TF-IDF 벡터라이저를 사용하여 텍스트를 변환합니다.\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(texts)\n",
    "    \n",
    "    for text, row in zip(texts, tfidf_matrix):\n",
    "        words = text.split()\n",
    "        # TF-IDF 점수가 가장 낮은 단어의 인덱스를 찾습니다.\n",
    "        min_tfidf_idx = row.argmin()\n",
    "        # 교체할 단어를 선택합니다.\n",
    "        replace_word = tfidf_vectorizer.get_feature_names_out()[min_tfidf_idx]\n",
    "\n",
    "        # GloVe 모델을 사용하여 유사한 단어를 찾습니다.\n",
    "        synonym = glove_model.most_similar(replace_word)\n",
    "        if synonym:\n",
    "            synonym = synonym[0][0]  # 가장 유사한 단어를 선택합니다.\n",
    "            # 선택된 단어로 교체합니다.\n",
    "            words = [synonym if word == replace_word else word for word in words]\n",
    "        augmented_texts.append(' '.join(words))\n",
    "    \n",
    "    return augmented_texts\n",
    "\n",
    "# 데이터 전처리 및 증강을 수행하고, 모델 실행 결과를 반환하는 함수\n",
    "def preprocess_augment_and_run_model(num_words, augment, glove_path, train_glove, model_func):\n",
    "    # 데이터 로드 및 전처리\n",
    "    x_train, y_train, x_test, y_test = load_and_preprocess_data(num_words)\n",
    "    \n",
    "    # 증강 옵션에 따라 GloVe 모델을 로드하고 데이터 증강을 수행\n",
    "    if augment:\n",
    "        tokenized_sentences = [text.lower().split() for text in x_train]\n",
    "        glove_model = initialize_or_load_glove_model(tokenized_sentences, glove_path, train=train_glove)\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        tfidf_vectorizer.fit(x_train)\n",
    "        x_train_augmented = augment_data_by_replacing_words(x_train, glove_model, tfidf_vectorizer)\n",
    "        x_test_augmented = augment_data_by_replacing_words(x_test, glove_model, tfidf_vectorizer)\n",
    "    else:\n",
    "        x_train_augmented = x_train\n",
    "        x_test_augmented = x_test\n",
    "\n",
    "    # 모델 설정 및 그리드 서치 실행\n",
    "    model, params = model_func()\n",
    "    results = run_grid_search(model, params, x_train_augmented, y_train, x_test_augmented, y_test)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM 설정 함수\n",
    "def set_model_and_params_svm():\n",
    "    model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', SVC()),\n",
    "    ])\n",
    "    params = {\n",
    "        'clf__C': [0.1, 1.0, 10.0],\n",
    "        'clf__kernel': ['linear', 'rbf'],\n",
    "    }\n",
    "    return model, params\n",
    "\n",
    "# 그리드 서치 실행 및 결과 저장 함수\n",
    "def run_grid_search(model, params, x_train, y_train, x_test, y_test):\n",
    "    start_time = time.time()  # 시작 시간 기록\n",
    "    grid_search = GridSearchCV(model, params, n_jobs=-1, cv=5)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    test_score = best_model.score(x_test, y_test)\n",
    "    end_time = time.time()  # 종료 시간 기록\n",
    "    elapsed_time = end_time - start_time  # 경과 시간 계산\n",
    "    return {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'test_score': test_score,\n",
    "        'elapsed_time': elapsed_time  # 경과 시간 추가\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화 함수 (수정)\n",
    "def plot_results(results):\n",
    "    # 결과를 정렬하여 표시합니다.\n",
    "    sorted_labels = sorted(results.keys(), key=lambda x: (results[x]['test_score'], results[x]['elapsed_time']), reverse=True)\n",
    "    \n",
    "    # Test Accuracy와 실행 시간을 분리하여 리스트로 만듭니다.\n",
    "    labels = []\n",
    "    test_scores = []\n",
    "    times = []\n",
    "    for label in sorted_labels:\n",
    "        labels.append(label.replace('_', ' ').title())  # 레이블을 보기 좋게 처리합니다.\n",
    "        test_scores.append(results[label]['test_score'])\n",
    "        times.append(results[label]['elapsed_time'])\n",
    "\n",
    "    # 그래프 사이즈를 조정합니다.\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Test Accuracy 막대 그래프를 그립니다.\n",
    "    y_positions = np.arange(len(labels))\n",
    "    bars = ax1.barh(y_positions, test_scores, color='skyblue', label='Test Accuracy')\n",
    "    ax1.set_yticks(y_positions)\n",
    "    ax1.set_yticklabels(labels)\n",
    "    ax1.invert_yaxis()  # 레이블을 높은 정확도가 위로 오도록 뒤집습니다.\n",
    "    ax1.set_xlabel('Test Accuracy', color='skyblue')\n",
    "    ax1.tick_params(axis='x', labelcolor='skyblue')\n",
    "\n",
    "    # 막대 그래프에 정확도 값을 표시합니다.\n",
    "    for bar, score in zip(bars, test_scores):\n",
    "        ax1.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, \n",
    "                 '{0:.2f}'.format(score), \n",
    "                 va='center', ha='right', color='blue', fontsize=8)\n",
    "\n",
    "    # 실행 시간 라인 그래프를 그립니다.\n",
    "    ax2 = ax1.twiny()  # x 축을 공유하는 새 축을 생성합니다.\n",
    "    points = ax2.plot(times, y_positions, 'o', color='salmon', label='Time (s)')\n",
    "    ax2.set_xlabel('Time (s)', color='salmon')\n",
    "    ax2.tick_params(axis='x', labelcolor='salmon')\n",
    "\n",
    "    # 라인 그래프에 실행 시간 값을 표시합니다.\n",
    "    for time, pos in zip(times, y_positions):\n",
    "        ax2.text(time, pos, '{0:.2f}s'.format(time), \n",
    "                 va='center', ha='left', color='red', fontsize=8)\n",
    "\n",
    "    plt.title('Model Comparison: Accuracy and Execution Time')\n",
    "    fig.tight_layout()  # 그래프 레이아웃을 조정합니다.\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1699457657774,
     "user": {
      "displayName": "­김정현",
      "userId": "07015025296255556159"
     },
     "user_tz": -540
    },
    "id": "BxFAYaiIiLM4"
   },
   "outputs": [],
   "source": [
    "# Main execution function\n",
    "def main():\n",
    "    num_words = 10000\n",
    "    glove_input_file = 'glove.6B.100d.txt'  # 실제 경로로 변경해야 합니다.\n",
    "    word2vec_output_file = 'glove.6B.100d.word2vec.txt'  # 변환된 파일의 경로\n",
    "\n",
    "    # 데이터 증강 전 모델 실행 결과\n",
    "    results_before_augmentation = preprocess_augment_and_run_model(\n",
    "        num_words, augment=False, glove_path=glove_input_file, train_glove=False,\n",
    "        model_func=set_model_and_params_svm\n",
    "    )\n",
    "    \n",
    "    # 데이터 증강 후 모델 실행 결과\n",
    "    results_after_augmentation = preprocess_augment_and_run_model(\n",
    "        num_words, augment=True, glove_path=glove_input_file, train_glove=False,\n",
    "        model_func=set_model_and_params_svm\n",
    "    )\n",
    "    \n",
    "    # 결과 시각화\n",
    "    all_results = {\n",
    "        'before_augmentation': results_before_augmentation,\n",
    "        'after_augmentation': results_after_augmentation\n",
    "    }\n",
    "    plot_results(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPl4doTPV13ArWpCtP87Jre",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1YOX2NGbe5p14HWgZe6A4a-eZF_J8nunO",
     "timestamp": 1699456985715
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
